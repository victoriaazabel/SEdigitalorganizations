{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoriaazabel/SEdigitalorganizations/blob/main/VictoriaZabel_homework_3_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "fastbook.setup_book()"
      ],
      "metadata": {
        "id": "HhmY7I5M8VJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53e9b49-6e19-466d-9b2c-86b5dd886656"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Artificial Neural Networks\n",
        "\n",
        "Please read the introdcution of neuronal networks of the book *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow*, p. 299-316.\n",
        "\n",
        "1. Why have neural networks, even though they were invented early on, only now caught on?\n",
        "\n",
        "2. What is a percepton and a threshold logic unit (TLU)? Try to define a linear function and a step function of your choice, use some values of your choice and explain what might be the result of the percepton. (maybe using max. two TLU's)\n",
        "\n",
        "3. What is a fully connected layer and an output layer? Why can we easily combine the equations of multiple instances into a fully connected layer?\n",
        "\n",
        "4. What problem did Marvin Minsky and Seymour Paper highlight that perceptrons could not solve? What is a possible solution?\n",
        "\n",
        "5. What is a deep neuronal network? What are hidden layers? What means feedforward neural network (FNN).\n",
        "\n",
        "6. Try to explain how backpropagation works! (In Addition, you can have a look to the following example, which tries manually to compute the backprogation of a simple linear network. https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/ OR you can also read through the Google Colab [04_mnist_basics.ipynb](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb#scrollTo=t1DK6o-gckCy))\n",
        "\n",
        "6. Why do we need activation functions, wouldn't it be easier just using linear functions?\n"
      ],
      "metadata": {
        "id": "_Rdj49uwjuoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answers\n",
        "\n",
        "1. Neural networks, although invented in 1943, have only recently caught on. This is because many other architectures and training techniques were created that were more powerful and offered better results. This caused the progress of neural networks to slow down. Nowadays, there is more data as well as increased computing power, meaning that neural networks are more successful in working on large and complex machine learning projects. Among others, the improvement in training algorithms has had a positive impact on neural networks of today.\n",
        "\n",
        "2. Percepton and Threshold Logic Units (TLU's) are simple artificial neural networks, with perceptons being based on TLU's. In their cases the inputs are numeric values rather than binary ones. Perceptons commonly use the Heaviside Step Function, whereas TLU's can be used for simple linear binary classification. A linear function could be z = w⊺ x + b. The result of which will be applied to the step function, in our example the Heavyside Step Function, using input weights (w) and the bias (b) as parameters (= step(z)). Example inputs would be 1, 2, and 3 weighted at 2, 4, 8 respectively. After applying the weights to the inputs, the step function and the bias are applied to the outcome which will have the values of 0 or 1, 0 if z < 0 and 1 if z > 0.\n",
        "\n",
        "3. A fully connected, or dense, layer is a perceptron composed of one or more TLU's compromised into one layer. In this case, every TLU is connected to every input (input layer). An output layer on the other hand, is the final output produced by the layer of TLU's. Combining equations of multiple instances into a fully connected layer can be done because of linear algebra, specifically matrices. One example of this is done by “broadcasting” in which the process of adding a vector to a matrix allows you to add it to every row within the matrix.\n",
        "\n",
        "4. According to Marvin Minsky and Seymour Paper, perceptrons cannot solve the problem of solving trivial problems, such as exclusive OR (XOR) problems. Although this is also the case for other linear classification models, perceptrons were held to a higher regard leading to a greater disapointment. However, a possible solution of this would be using Multilayer Perceptrons (MLP's) that stack multiple perceptrons and are able to solve XOR problems.\n",
        "\n",
        "5. A deep neuronal network is a type of artificial neural network that contains multiple, or a \"deep stack\", of hidden layers. While it used to mean a network with two or more hidden layers, nowadays the definition and boundaries of hidden layers in neural networks is unclear. As such, hidden layers are the TLU layers between the input and the final TLU layer (output layer) and are categorized into lower layers if closer to the input and upper layers if closer to the output. Feedforward Neural Network (FNN) are architectures in which the signal flows from the inputs to the outputs, namely in in one direction. \n",
        "\n",
        "6. Backpropagation is an algorithm used when training feedforward neural networks. Here, the derivative of layers in neural networks is calculated. It is a combination of reverse-mode autodiff and gradient descent to improve weights connection and using error gradients in order to train neural networks.\n",
        "\n",
        "7. Activation functions, such as the sigmoid function, are needed because they are able to solve complex problems and develop complex representations.\n",
        "Using linear functions would not be easier because the chaining of multiple linear functions will only result in more linear functions, meaning that you would not be able to solve complex problems. Thus, with the absence of activation functions, neural networks would work with their inputs as a linear regression model would. The main difference here is that you are able to differentiate a function, which makes less sense in a linear function as this would result in a constant."
      ],
      "metadata": {
        "id": "56BP6ZP9Jkxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ideas for the learning portfolio:\n",
        "\n",
        "1) For example, you could train a single TLU to classify iris flowers based on petal length and width in the !!!pyTorch!! environment.\n",
        "\n",
        "2) You could add to our king county housepricing ML project a neuronal network and compare it to the other models."
      ],
      "metadata": {
        "id": "QpROdC2rJVmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "4tF8YDV3T91n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A traditional approach: training a digit classifier and learning pyTorch tensors.\n",
        "\n",
        "For this assignment, I ask you to read the Google Colab [04_mnist_basics.ipynb](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb#scrollTo=t1DK6o-gckCy) to the beginning of the chapter *Stochastic Gradient Descent (SGD)*. \n",
        "\n",
        "First, try to summarize what we know about pyTorch tensors by trying to predict whether we have a 1 or a 7 in the MNIST dataset using a traditional rule-based programming approach. Therefore use pyTorch tensors for the entire tasks and fulfill the following steps:\n",
        "\n",
        "1) Randomly split the MNIST dataset (1 and 7) into a training dataset and a test dataset in a ratio of 80:20.\n",
        "\n",
        "2) Instead of using an optimal 1 or 7 with the mean over the training dataset, try to calculate the sum of the distances to all instances in the training set for each instance in the test dataset. You can use the L2 norm. \n",
        "\n",
        "3) For each instance in the test set, decide if it is a 1 or 7 and calculate the precision.\n",
        "\n",
        "Do we get a similar good result?\n"
      ],
      "metadata": {
        "id": "h6OwXNEeed93"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Hrrgv9OVebAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc47e8d2-3d6f-4f1b-ac85-07f48f4249f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('training'),Path('testing')]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# From 04 MNIST: experimenting with the dataset before answering the questions\n",
        "\n",
        "#path = untar_data(URLs.MNIST_SAMPLE) # only contains 3 and 7 cuz of sample so...\n",
        "path = untar_data(URLs.MNIST)\n",
        "\n",
        "#hide\n",
        "Path.BASE_PATH = path\n",
        "\n",
        "path.ls()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[Path('cleaned.csv'),Path('item_list.txt'),Path('trained_model.pkl'),Path('models'),Path('valid'),Path('labels.csv'),Path('export.pkl'),Path('history.csv'),Path('train')]\n",
        "\n",
        "(path/'training').ls()\n",
        "\n",
        "[Path('training/7'),Path('training/1')]\n",
        "\n",
        "one = (path/'training'/'1').ls().sorted()\n",
        "seven = (path/'training'/'7').ls().sorted()\n",
        "one\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrm24srNaSta",
        "outputId": "f560ec9a-68ff-448a-f9b6-e47d3c21e567"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#6742) [Path('training/1/10006.png'),Path('training/1/10007.png'),Path('training/1/1002.png'),Path('training/1/10020.png'),Path('training/1/10027.png'),Path('training/1/1003.png'),Path('training/1/10040.png'),Path('training/1/10048.png'),Path('training/1/10058.png'),Path('training/1/10067.png')...]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#im1_path = one[1]\n",
        "#im1 = Image.open(im1_path)\n",
        "#im1\n",
        "\n",
        "im7_path = seven[1]\n",
        "im7 = Image.open(im7_path)\n",
        "im7\n",
        "\n",
        "#array(im7)[4:10,4:10]\n",
        "\n",
        "tensor(im7)[4:10,4:10]\n",
        "\n",
        "im7_t = tensor(im7)\n",
        "df = pd.DataFrame(im7_t[4:15,4:22])\n",
        "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greens')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "5COkM2g1bzCs",
        "outputId": "942ce8ce-2ee0-483f-af20-d20723cab0bc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f63989f57f0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_720a4_row0_col0, #T_720a4_row0_col1, #T_720a4_row0_col2, #T_720a4_row0_col3, #T_720a4_row0_col4, #T_720a4_row0_col5, #T_720a4_row0_col6, #T_720a4_row0_col7, #T_720a4_row0_col8, #T_720a4_row0_col9, #T_720a4_row0_col10, #T_720a4_row0_col11, #T_720a4_row0_col12, #T_720a4_row0_col13, #T_720a4_row0_col14, #T_720a4_row0_col15, #T_720a4_row0_col16, #T_720a4_row0_col17, #T_720a4_row1_col0, #T_720a4_row1_col1, #T_720a4_row1_col2, #T_720a4_row1_col3, #T_720a4_row1_col4, #T_720a4_row1_col5, #T_720a4_row1_col6, #T_720a4_row1_col7, #T_720a4_row1_col8, #T_720a4_row1_col9, #T_720a4_row1_col10, #T_720a4_row1_col11, #T_720a4_row1_col12, #T_720a4_row1_col13, #T_720a4_row1_col14, #T_720a4_row1_col15, #T_720a4_row1_col16, #T_720a4_row1_col17, #T_720a4_row2_col0, #T_720a4_row2_col1, #T_720a4_row2_col2, #T_720a4_row2_col3, #T_720a4_row2_col4, #T_720a4_row2_col5, #T_720a4_row2_col6, #T_720a4_row2_col10, #T_720a4_row2_col11, #T_720a4_row2_col12, #T_720a4_row2_col13, #T_720a4_row2_col14, #T_720a4_row2_col15, #T_720a4_row3_col0, #T_720a4_row3_col1, #T_720a4_row3_col2, #T_720a4_row3_col3, #T_720a4_row3_col4, #T_720a4_row3_col5, #T_720a4_row3_col10, #T_720a4_row3_col11, #T_720a4_row3_col12, #T_720a4_row3_col13, #T_720a4_row3_col14, #T_720a4_row4_col0, #T_720a4_row4_col1, #T_720a4_row4_col2, #T_720a4_row4_col3, #T_720a4_row4_col4, #T_720a4_row4_col11, #T_720a4_row4_col12, #T_720a4_row4_col13, #T_720a4_row5_col0, #T_720a4_row5_col1, #T_720a4_row5_col2, #T_720a4_row5_col3, #T_720a4_row5_col4, #T_720a4_row6_col0, #T_720a4_row6_col1, #T_720a4_row6_col2, #T_720a4_row7_col0, #T_720a4_row7_col1, #T_720a4_row8_col0, #T_720a4_row8_col1, #T_720a4_row9_col0, #T_720a4_row9_col1, #T_720a4_row9_col9, #T_720a4_row9_col10, #T_720a4_row9_col11, #T_720a4_row9_col17, #T_720a4_row10_col0, #T_720a4_row10_col1, #T_720a4_row10_col6, #T_720a4_row10_col7, #T_720a4_row10_col8, #T_720a4_row10_col9, #T_720a4_row10_col10, #T_720a4_row10_col16, #T_720a4_row10_col17 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #f7fcf5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row2_col7, #T_720a4_row2_col16 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #f6fcf4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row2_col8 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #f0f9ec;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row2_col9 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #f3faf0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row2_col17 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #a4da9e;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row3_col6 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #eff9eb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row3_col7, #T_720a4_row10_col3 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #43ac5e;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row3_col8, #T_720a4_row3_col17, #T_720a4_row4_col7, #T_720a4_row4_col8, #T_720a4_row4_col16, #T_720a4_row4_col17, #T_720a4_row5_col7, #T_720a4_row5_col14, #T_720a4_row5_col15, #T_720a4_row5_col16, #T_720a4_row5_col17, #T_720a4_row6_col12, #T_720a4_row6_col13, #T_720a4_row6_col14, #T_720a4_row6_col15, #T_720a4_row6_col16, #T_720a4_row6_col17, #T_720a4_row7_col4, #T_720a4_row7_col5, #T_720a4_row7_col6, #T_720a4_row7_col7, #T_720a4_row7_col8, #T_720a4_row7_col9, #T_720a4_row7_col10, #T_720a4_row7_col11, #T_720a4_row7_col12, #T_720a4_row7_col13, #T_720a4_row7_col14, #T_720a4_row7_col15, #T_720a4_row7_col16, #T_720a4_row8_col3, #T_720a4_row8_col4, #T_720a4_row8_col5, #T_720a4_row8_col7, #T_720a4_row8_col14, #T_720a4_row8_col15, #T_720a4_row9_col2, #T_720a4_row9_col3, #T_720a4_row9_col4, #T_720a4_row9_col13, #T_720a4_row9_col14, #T_720a4_row10_col13, #T_720a4_row10_col14 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #00441b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row3_col9 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #1c8540;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row3_col15 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #edf8e9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row3_col16 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #6dc072;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row4_col5 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #f2faef;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row4_col6 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #03702e;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row4_col9 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #006328;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row4_col10 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #95d391;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row4_col14 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #c6e8bf;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row4_col15 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #077331;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row5_col5, #T_720a4_row8_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #37a055;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row5_col6, #T_720a4_row6_col6, #T_720a4_row8_col6, #T_720a4_row8_col8, #T_720a4_row9_col15 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #00451c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row5_col8 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #006227;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row5_col9 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #76c578;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row5_col10, #T_720a4_row6_col3 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #ddf2d8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row5_col11, #T_720a4_row7_col2 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #f1faee;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row5_col12, #T_720a4_row6_col9 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #c0e6b9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row5_col13 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #2d954d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row6_col4 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #2a924a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row6_col5 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #00481d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row6_col7 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #00682a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row6_col8 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #b2e0ac;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row6_col10 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #2e964d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row6_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #006428;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row7_col3 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #107a37;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row7_col17 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #238b45;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row8_col2 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #a8dca2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row8_col9 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #00491d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row8_col10 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #0c7735;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row8_col12 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #78c679;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row8_col13 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #39a257;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row8_col16 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #005522;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row8_col17 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #e2f4dd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row9_col5 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #2c944c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row9_col6, #T_720a4_row9_col7 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #b7e2b1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row9_col8 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #d6efd0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row9_col12 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #72c375;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row9_col16 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #cdecc7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row10_col2 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #eaf7e6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row10_col4 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #1e8741;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row10_col5 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #e7f6e2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row10_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #bae3b3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_720a4_row10_col12 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #004c1e;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_720a4_row10_col15 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #60ba6c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_720a4\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_720a4_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
              "      <th id=\"T_720a4_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
              "      <th id=\"T_720a4_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
              "      <th id=\"T_720a4_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
              "      <th id=\"T_720a4_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
              "      <th id=\"T_720a4_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
              "      <th id=\"T_720a4_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
              "      <th id=\"T_720a4_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
              "      <th id=\"T_720a4_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
              "      <th id=\"T_720a4_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
              "      <th id=\"T_720a4_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
              "      <th id=\"T_720a4_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
              "      <th id=\"T_720a4_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
              "      <th id=\"T_720a4_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
              "      <th id=\"T_720a4_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n",
              "      <th id=\"T_720a4_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n",
              "      <th id=\"T_720a4_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n",
              "      <th id=\"T_720a4_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_720a4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_720a4_row0_col0\" class=\"data row0 col0\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col2\" class=\"data row0 col2\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col3\" class=\"data row0 col3\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col4\" class=\"data row0 col4\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col5\" class=\"data row0 col5\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col6\" class=\"data row0 col6\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col7\" class=\"data row0 col7\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col8\" class=\"data row0 col8\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col9\" class=\"data row0 col9\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col10\" class=\"data row0 col10\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col11\" class=\"data row0 col11\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col12\" class=\"data row0 col12\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col13\" class=\"data row0 col13\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col14\" class=\"data row0 col14\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col15\" class=\"data row0 col15\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col16\" class=\"data row0 col16\" >0</td>\n",
              "      <td id=\"T_720a4_row0_col17\" class=\"data row0 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_720a4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_720a4_row1_col0\" class=\"data row1 col0\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col2\" class=\"data row1 col2\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col3\" class=\"data row1 col3\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col4\" class=\"data row1 col4\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col5\" class=\"data row1 col5\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col6\" class=\"data row1 col6\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col7\" class=\"data row1 col7\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col8\" class=\"data row1 col8\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col9\" class=\"data row1 col9\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col10\" class=\"data row1 col10\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col11\" class=\"data row1 col11\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col12\" class=\"data row1 col12\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col13\" class=\"data row1 col13\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col14\" class=\"data row1 col14\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col15\" class=\"data row1 col15\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col16\" class=\"data row1 col16\" >0</td>\n",
              "      <td id=\"T_720a4_row1_col17\" class=\"data row1 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_720a4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_720a4_row2_col0\" class=\"data row2 col0\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col2\" class=\"data row2 col2\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col3\" class=\"data row2 col3\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col4\" class=\"data row2 col4\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col5\" class=\"data row2 col5\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col6\" class=\"data row2 col6\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col7\" class=\"data row2 col7\" >1</td>\n",
              "      <td id=\"T_720a4_row2_col8\" class=\"data row2 col8\" >13</td>\n",
              "      <td id=\"T_720a4_row2_col9\" class=\"data row2 col9\" >7</td>\n",
              "      <td id=\"T_720a4_row2_col10\" class=\"data row2 col10\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col11\" class=\"data row2 col11\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col12\" class=\"data row2 col12\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col13\" class=\"data row2 col13\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col14\" class=\"data row2 col14\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col15\" class=\"data row2 col15\" >0</td>\n",
              "      <td id=\"T_720a4_row2_col16\" class=\"data row2 col16\" >2</td>\n",
              "      <td id=\"T_720a4_row2_col17\" class=\"data row2 col17\" >93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_720a4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_720a4_row3_col0\" class=\"data row3 col0\" >0</td>\n",
              "      <td id=\"T_720a4_row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "      <td id=\"T_720a4_row3_col2\" class=\"data row3 col2\" >0</td>\n",
              "      <td id=\"T_720a4_row3_col3\" class=\"data row3 col3\" >0</td>\n",
              "      <td id=\"T_720a4_row3_col4\" class=\"data row3 col4\" >0</td>\n",
              "      <td id=\"T_720a4_row3_col5\" class=\"data row3 col5\" >0</td>\n",
              "      <td id=\"T_720a4_row3_col6\" class=\"data row3 col6\" >15</td>\n",
              "      <td id=\"T_720a4_row3_col7\" class=\"data row3 col7\" >157</td>\n",
              "      <td id=\"T_720a4_row3_col8\" class=\"data row3 col8\" >254</td>\n",
              "      <td id=\"T_720a4_row3_col9\" class=\"data row3 col9\" >197</td>\n",
              "      <td id=\"T_720a4_row3_col10\" class=\"data row3 col10\" >0</td>\n",
              "      <td id=\"T_720a4_row3_col11\" class=\"data row3 col11\" >0</td>\n",
              "      <td id=\"T_720a4_row3_col12\" class=\"data row3 col12\" >0</td>\n",
              "      <td id=\"T_720a4_row3_col13\" class=\"data row3 col13\" >0</td>\n",
              "      <td id=\"T_720a4_row3_col14\" class=\"data row3 col14\" >0</td>\n",
              "      <td id=\"T_720a4_row3_col15\" class=\"data row3 col15\" >18</td>\n",
              "      <td id=\"T_720a4_row3_col16\" class=\"data row3 col16\" >131</td>\n",
              "      <td id=\"T_720a4_row3_col17\" class=\"data row3 col17\" >254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_720a4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_720a4_row4_col0\" class=\"data row4 col0\" >0</td>\n",
              "      <td id=\"T_720a4_row4_col1\" class=\"data row4 col1\" >0</td>\n",
              "      <td id=\"T_720a4_row4_col2\" class=\"data row4 col2\" >0</td>\n",
              "      <td id=\"T_720a4_row4_col3\" class=\"data row4 col3\" >0</td>\n",
              "      <td id=\"T_720a4_row4_col4\" class=\"data row4 col4\" >0</td>\n",
              "      <td id=\"T_720a4_row4_col5\" class=\"data row4 col5\" >9</td>\n",
              "      <td id=\"T_720a4_row4_col6\" class=\"data row4 col6\" >220</td>\n",
              "      <td id=\"T_720a4_row4_col7\" class=\"data row4 col7\" >254</td>\n",
              "      <td id=\"T_720a4_row4_col8\" class=\"data row4 col8\" >254</td>\n",
              "      <td id=\"T_720a4_row4_col9\" class=\"data row4 col9\" >230</td>\n",
              "      <td id=\"T_720a4_row4_col10\" class=\"data row4 col10\" >104</td>\n",
              "      <td id=\"T_720a4_row4_col11\" class=\"data row4 col11\" >0</td>\n",
              "      <td id=\"T_720a4_row4_col12\" class=\"data row4 col12\" >0</td>\n",
              "      <td id=\"T_720a4_row4_col13\" class=\"data row4 col13\" >0</td>\n",
              "      <td id=\"T_720a4_row4_col14\" class=\"data row4 col14\" >65</td>\n",
              "      <td id=\"T_720a4_row4_col15\" class=\"data row4 col15\" >216</td>\n",
              "      <td id=\"T_720a4_row4_col16\" class=\"data row4 col16\" >254</td>\n",
              "      <td id=\"T_720a4_row4_col17\" class=\"data row4 col17\" >254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_720a4_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_720a4_row5_col0\" class=\"data row5 col0\" >0</td>\n",
              "      <td id=\"T_720a4_row5_col1\" class=\"data row5 col1\" >0</td>\n",
              "      <td id=\"T_720a4_row5_col2\" class=\"data row5 col2\" >0</td>\n",
              "      <td id=\"T_720a4_row5_col3\" class=\"data row5 col3\" >0</td>\n",
              "      <td id=\"T_720a4_row5_col4\" class=\"data row5 col4\" >0</td>\n",
              "      <td id=\"T_720a4_row5_col5\" class=\"data row5 col5\" >169</td>\n",
              "      <td id=\"T_720a4_row5_col6\" class=\"data row5 col6\" >254</td>\n",
              "      <td id=\"T_720a4_row5_col7\" class=\"data row5 col7\" >254</td>\n",
              "      <td id=\"T_720a4_row5_col8\" class=\"data row5 col8\" >231</td>\n",
              "      <td id=\"T_720a4_row5_col9\" class=\"data row5 col9\" >126</td>\n",
              "      <td id=\"T_720a4_row5_col10\" class=\"data row5 col10\" >40</td>\n",
              "      <td id=\"T_720a4_row5_col11\" class=\"data row5 col11\" >11</td>\n",
              "      <td id=\"T_720a4_row5_col12\" class=\"data row5 col12\" >70</td>\n",
              "      <td id=\"T_720a4_row5_col13\" class=\"data row5 col13\" >180</td>\n",
              "      <td id=\"T_720a4_row5_col14\" class=\"data row5 col14\" >254</td>\n",
              "      <td id=\"T_720a4_row5_col15\" class=\"data row5 col15\" >254</td>\n",
              "      <td id=\"T_720a4_row5_col16\" class=\"data row5 col16\" >254</td>\n",
              "      <td id=\"T_720a4_row5_col17\" class=\"data row5 col17\" >254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_720a4_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_720a4_row6_col0\" class=\"data row6 col0\" >0</td>\n",
              "      <td id=\"T_720a4_row6_col1\" class=\"data row6 col1\" >0</td>\n",
              "      <td id=\"T_720a4_row6_col2\" class=\"data row6 col2\" >0</td>\n",
              "      <td id=\"T_720a4_row6_col3\" class=\"data row6 col3\" >40</td>\n",
              "      <td id=\"T_720a4_row6_col4\" class=\"data row6 col4\" >183</td>\n",
              "      <td id=\"T_720a4_row6_col5\" class=\"data row6 col5\" >251</td>\n",
              "      <td id=\"T_720a4_row6_col6\" class=\"data row6 col6\" >254</td>\n",
              "      <td id=\"T_720a4_row6_col7\" class=\"data row6 col7\" >226</td>\n",
              "      <td id=\"T_720a4_row6_col8\" class=\"data row6 col8\" >81</td>\n",
              "      <td id=\"T_720a4_row6_col9\" class=\"data row6 col9\" >70</td>\n",
              "      <td id=\"T_720a4_row6_col10\" class=\"data row6 col10\" >180</td>\n",
              "      <td id=\"T_720a4_row6_col11\" class=\"data row6 col11\" >229</td>\n",
              "      <td id=\"T_720a4_row6_col12\" class=\"data row6 col12\" >254</td>\n",
              "      <td id=\"T_720a4_row6_col13\" class=\"data row6 col13\" >254</td>\n",
              "      <td id=\"T_720a4_row6_col14\" class=\"data row6 col14\" >254</td>\n",
              "      <td id=\"T_720a4_row6_col15\" class=\"data row6 col15\" >254</td>\n",
              "      <td id=\"T_720a4_row6_col16\" class=\"data row6 col16\" >254</td>\n",
              "      <td id=\"T_720a4_row6_col17\" class=\"data row6 col17\" >254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_720a4_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_720a4_row7_col0\" class=\"data row7 col0\" >0</td>\n",
              "      <td id=\"T_720a4_row7_col1\" class=\"data row7 col1\" >0</td>\n",
              "      <td id=\"T_720a4_row7_col2\" class=\"data row7 col2\" >7</td>\n",
              "      <td id=\"T_720a4_row7_col3\" class=\"data row7 col3\" >208</td>\n",
              "      <td id=\"T_720a4_row7_col4\" class=\"data row7 col4\" >254</td>\n",
              "      <td id=\"T_720a4_row7_col5\" class=\"data row7 col5\" >254</td>\n",
              "      <td id=\"T_720a4_row7_col6\" class=\"data row7 col6\" >255</td>\n",
              "      <td id=\"T_720a4_row7_col7\" class=\"data row7 col7\" >254</td>\n",
              "      <td id=\"T_720a4_row7_col8\" class=\"data row7 col8\" >254</td>\n",
              "      <td id=\"T_720a4_row7_col9\" class=\"data row7 col9\" >254</td>\n",
              "      <td id=\"T_720a4_row7_col10\" class=\"data row7 col10\" >255</td>\n",
              "      <td id=\"T_720a4_row7_col11\" class=\"data row7 col11\" >254</td>\n",
              "      <td id=\"T_720a4_row7_col12\" class=\"data row7 col12\" >254</td>\n",
              "      <td id=\"T_720a4_row7_col13\" class=\"data row7 col13\" >254</td>\n",
              "      <td id=\"T_720a4_row7_col14\" class=\"data row7 col14\" >254</td>\n",
              "      <td id=\"T_720a4_row7_col15\" class=\"data row7 col15\" >254</td>\n",
              "      <td id=\"T_720a4_row7_col16\" class=\"data row7 col16\" >254</td>\n",
              "      <td id=\"T_720a4_row7_col17\" class=\"data row7 col17\" >190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_720a4_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_720a4_row8_col0\" class=\"data row8 col0\" >0</td>\n",
              "      <td id=\"T_720a4_row8_col1\" class=\"data row8 col1\" >0</td>\n",
              "      <td id=\"T_720a4_row8_col2\" class=\"data row8 col2\" >53</td>\n",
              "      <td id=\"T_720a4_row8_col3\" class=\"data row8 col3\" >254</td>\n",
              "      <td id=\"T_720a4_row8_col4\" class=\"data row8 col4\" >254</td>\n",
              "      <td id=\"T_720a4_row8_col5\" class=\"data row8 col5\" >254</td>\n",
              "      <td id=\"T_720a4_row8_col6\" class=\"data row8 col6\" >254</td>\n",
              "      <td id=\"T_720a4_row8_col7\" class=\"data row8 col7\" >254</td>\n",
              "      <td id=\"T_720a4_row8_col8\" class=\"data row8 col8\" >253</td>\n",
              "      <td id=\"T_720a4_row8_col9\" class=\"data row8 col9\" >250</td>\n",
              "      <td id=\"T_720a4_row8_col10\" class=\"data row8 col10\" >212</td>\n",
              "      <td id=\"T_720a4_row8_col11\" class=\"data row8 col11\" >169</td>\n",
              "      <td id=\"T_720a4_row8_col12\" class=\"data row8 col12\" >125</td>\n",
              "      <td id=\"T_720a4_row8_col13\" class=\"data row8 col13\" >167</td>\n",
              "      <td id=\"T_720a4_row8_col14\" class=\"data row8 col14\" >254</td>\n",
              "      <td id=\"T_720a4_row8_col15\" class=\"data row8 col15\" >254</td>\n",
              "      <td id=\"T_720a4_row8_col16\" class=\"data row8 col16\" >241</td>\n",
              "      <td id=\"T_720a4_row8_col17\" class=\"data row8 col17\" >35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_720a4_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_720a4_row9_col0\" class=\"data row9 col0\" >0</td>\n",
              "      <td id=\"T_720a4_row9_col1\" class=\"data row9 col1\" >0</td>\n",
              "      <td id=\"T_720a4_row9_col2\" class=\"data row9 col2\" >150</td>\n",
              "      <td id=\"T_720a4_row9_col3\" class=\"data row9 col3\" >254</td>\n",
              "      <td id=\"T_720a4_row9_col4\" class=\"data row9 col4\" >254</td>\n",
              "      <td id=\"T_720a4_row9_col5\" class=\"data row9 col5\" >181</td>\n",
              "      <td id=\"T_720a4_row9_col6\" class=\"data row9 col6\" >77</td>\n",
              "      <td id=\"T_720a4_row9_col7\" class=\"data row9 col7\" >77</td>\n",
              "      <td id=\"T_720a4_row9_col8\" class=\"data row9 col8\" >48</td>\n",
              "      <td id=\"T_720a4_row9_col9\" class=\"data row9 col9\" >0</td>\n",
              "      <td id=\"T_720a4_row9_col10\" class=\"data row9 col10\" >0</td>\n",
              "      <td id=\"T_720a4_row9_col11\" class=\"data row9 col11\" >0</td>\n",
              "      <td id=\"T_720a4_row9_col12\" class=\"data row9 col12\" >128</td>\n",
              "      <td id=\"T_720a4_row9_col13\" class=\"data row9 col13\" >254</td>\n",
              "      <td id=\"T_720a4_row9_col14\" class=\"data row9 col14\" >254</td>\n",
              "      <td id=\"T_720a4_row9_col15\" class=\"data row9 col15\" >253</td>\n",
              "      <td id=\"T_720a4_row9_col16\" class=\"data row9 col16\" >57</td>\n",
              "      <td id=\"T_720a4_row9_col17\" class=\"data row9 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_720a4_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_720a4_row10_col0\" class=\"data row10 col0\" >0</td>\n",
              "      <td id=\"T_720a4_row10_col1\" class=\"data row10 col1\" >0</td>\n",
              "      <td id=\"T_720a4_row10_col2\" class=\"data row10 col2\" >14</td>\n",
              "      <td id=\"T_720a4_row10_col3\" class=\"data row10 col3\" >157</td>\n",
              "      <td id=\"T_720a4_row10_col4\" class=\"data row10 col4\" >195</td>\n",
              "      <td id=\"T_720a4_row10_col5\" class=\"data row10 col5\" >29</td>\n",
              "      <td id=\"T_720a4_row10_col6\" class=\"data row10 col6\" >0</td>\n",
              "      <td id=\"T_720a4_row10_col7\" class=\"data row10 col7\" >0</td>\n",
              "      <td id=\"T_720a4_row10_col8\" class=\"data row10 col8\" >0</td>\n",
              "      <td id=\"T_720a4_row10_col9\" class=\"data row10 col9\" >0</td>\n",
              "      <td id=\"T_720a4_row10_col10\" class=\"data row10 col10\" >0</td>\n",
              "      <td id=\"T_720a4_row10_col11\" class=\"data row10 col11\" >75</td>\n",
              "      <td id=\"T_720a4_row10_col12\" class=\"data row10 col12\" >248</td>\n",
              "      <td id=\"T_720a4_row10_col13\" class=\"data row10 col13\" >254</td>\n",
              "      <td id=\"T_720a4_row10_col14\" class=\"data row10 col14\" >254</td>\n",
              "      <td id=\"T_720a4_row10_col15\" class=\"data row10 col15\" >139</td>\n",
              "      <td id=\"T_720a4_row10_col16\" class=\"data row10 col16\" >0</td>\n",
              "      <td id=\"T_720a4_row10_col17\" class=\"data row10 col17\" >0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. \n",
        "\n",
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "training_set7, validation_set7 = torch.utils.data.random_split(seven, [0.8, 0.2])\n",
        "\n",
        "training_set1, validation_set1 = torch.utils.data.random_split(one, [0.8, 0.2])"
      ],
      "metadata": {
        "id": "NJwm7kRndQXQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.\n",
        "\n",
        "tensors7 = [tensor(Image.open(o)) for o in training_set7]\n",
        "tensors1 = [tensor(Image.open(o)) for o in training_set1]\n",
        "len(tensors1),len(tensors7)\n",
        "\n",
        "stacked7 = torch.stack(tensors7).float()/255\n",
        "stacked1 = torch.stack(tensors1).float()/255\n",
        "stacked1.shape\n",
        "\n",
        "mean7 = stacked7.mean(0)\n",
        "#show_image(mean7);\n",
        "\n",
        "mean1 = stacked1.mean(0)\n",
        "#show_image(mean1);\n",
        "\n",
        "a7 = stacked7[1]\n",
        "#show_image(a7);\n",
        "\n",
        "a1 = stacked7[1]\n",
        "\n",
        "l2n7 = ((a7 - mean7)**2).mean().sqrt()\n",
        "l2n7\n",
        "\n",
        "l2n1 = ((a1 - mean1)**2).mean().sqrt()\n",
        "l2n1\n",
        "\n",
        "print(l2n7, l2n1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GRtNESqep66",
        "outputId": "ea08fa09-4d58-4199-daa6-d16c9052652e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1833) tensor(0.3062)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. \n",
        "\n",
        "def mnist_distance(a,b): return (a-b).abs().mean((-1,-2))\n",
        "mnist_distance(a1, mean1)\n",
        "mnist_distance(a7, mean7)\n",
        "\n",
        "test1_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in validation_set1])\n",
        "test1_tens = test1_tens.float()/255\n",
        "test7_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in validation_set7])\n",
        "test7_tens = test7_tens.float()/255\n",
        "test1_tens.shape,test7_tens.shape\n",
        "\n",
        "def is_1(x): return mnist_distance(x, mean1) < mnist_distance(x, mean7)\n",
        "\n",
        "def is_7(x): return mnist_distance(x, mean7) < mnist_distance(x, mean1)\n",
        "\n",
        "distance_test1 = mnist_distance(test1_tens, mean1)\n",
        "distance_test1, distance_test1.shape\n",
        "\n",
        "is_1(a1), is_1(a1).float() # for a singlet hing this is false\n",
        "is_7(a7), is_7(a7).float() # \"\" true\n",
        "\n",
        "is_7(test7_tens)\n",
        "is_1(test1_tens)\n",
        "\n",
        "accuracy_1 = is_1(test1_tens).float() .mean()\n",
        "accuracy_7 = is_7(test7_tens).float().mean()\n",
        "\n",
        "accuracy_1, accuracy_7, (accuracy_1+accuracy_7) / 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYjznzy3i0Wd",
        "outputId": "3fcfd945-b348-4e43-b78d-f9b1762fd103"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.9985), tensor(0.8148), tensor(0.9067))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Gradient Descent (SGD)\n",
        "\n",
        "For this exercise I ask you to read the chapter Stochastic Gradient Descent (SGD) from the Google Colab 04_mnist_basics.ipynb in paralell. The chapter starts with a single TLU, compare p. 304 in \"Hands on Machine Learning\". Go through all 7 steps which are an easy example of how Stochastic Gradient Descent works.\n",
        "\n",
        "Our goal is to train a single TLU, which can decide if one number is larger then the other one. Therefore we create 100 random pairs with pyTorch and create a target vector which is eather 1 or 0.\n"
      ],
      "metadata": {
        "id": "ETcE9B9rdcEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Initialize the weights.\n",
        "\n",
        "2. For each image, use these weights to predict whether it appears to be a 3 or a 7.\n",
        "\n",
        "3. Based on these predictions, calculate how good the model is (its loss).\n",
        "\n",
        "4. Calculate the gradient, which measures for each weight, how changing that \n",
        "weight would change the loss\n",
        "\n",
        "5. Step (that is, change) all the weights based on that calculation.\n",
        "\n",
        "6. Go back to the step 2, and repeat the process.\n",
        "\n",
        "7. Iterate until you decide to stop the training process (for instance, because the model is good enough or you don't want to wait any longer)."
      ],
      "metadata": {
        "id": "NdMyFeyeq3-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((100, 2))\n",
        "y = torch.where(x[:,0] > x[:,1], 1.0, 0.0)\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "17qLyDnbpSbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c633c7e4-5c63-4571-c9ef-ae0d40cfa913"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0661, -0.2025],\n",
            "        [-0.6795,  0.0580],\n",
            "        [-0.4715,  1.3066],\n",
            "        [-0.5035, -0.9364],\n",
            "        [ 0.8816,  1.2512],\n",
            "        [-0.0529, -1.5510],\n",
            "        [ 1.1730, -1.0408],\n",
            "        [ 0.8998,  0.7058],\n",
            "        [ 0.6230, -0.7351],\n",
            "        [-1.5187, -0.9034],\n",
            "        [-0.4708,  0.7341],\n",
            "        [-0.6009,  0.5453],\n",
            "        [-2.0567, -0.7157],\n",
            "        [ 0.8060,  0.6183],\n",
            "        [ 1.7232,  1.0612],\n",
            "        [-0.5030,  0.2772],\n",
            "        [-0.3278,  1.1425],\n",
            "        [ 1.3275,  1.5741],\n",
            "        [-1.0005, -0.4779],\n",
            "        [ 0.7259, -1.2694],\n",
            "        [-1.1191, -1.6090],\n",
            "        [ 0.9179,  0.6802],\n",
            "        [ 0.8910, -0.5190],\n",
            "        [-1.5117,  1.6752],\n",
            "        [-0.7739,  0.7662],\n",
            "        [-1.0434,  0.9744],\n",
            "        [-0.2142, -0.5244],\n",
            "        [-1.4998, -0.9746],\n",
            "        [-0.2332, -1.6942],\n",
            "        [-0.4870,  0.7598],\n",
            "        [ 0.0228,  0.9663],\n",
            "        [ 0.6817,  2.6798],\n",
            "        [ 1.8297, -0.3295],\n",
            "        [-0.5554, -0.0344],\n",
            "        [-2.1779,  0.9070],\n",
            "        [ 1.3068, -1.0857],\n",
            "        [-0.8898,  0.2900],\n",
            "        [-0.3694,  0.9188],\n",
            "        [ 0.5302,  0.4374],\n",
            "        [ 0.8529, -1.2471],\n",
            "        [ 0.4918, -0.3945],\n",
            "        [-1.5183,  1.4828],\n",
            "        [-0.9940,  0.1492],\n",
            "        [ 0.7168, -0.5369],\n",
            "        [ 0.0807, -1.6461],\n",
            "        [-1.3298, -0.2278],\n",
            "        [ 1.1676,  0.2671],\n",
            "        [ 0.3350, -0.1052],\n",
            "        [-0.4920, -1.3067],\n",
            "        [ 1.8773,  0.2774],\n",
            "        [ 0.4214, -0.5877],\n",
            "        [-0.6079, -0.1474],\n",
            "        [-0.5199, -0.2634],\n",
            "        [ 0.1680, -2.2741],\n",
            "        [-0.9521, -0.1975],\n",
            "        [ 0.3863,  1.8387],\n",
            "        [-0.0837, -0.4086],\n",
            "        [ 0.6348, -0.7310],\n",
            "        [-1.9372,  0.7313],\n",
            "        [-1.1187, -0.3121],\n",
            "        [ 1.1814, -1.1495],\n",
            "        [ 1.2830, -0.8769],\n",
            "        [-1.8840,  1.7090],\n",
            "        [-0.8041,  0.1343],\n",
            "        [-0.1309, -0.9937],\n",
            "        [ 0.7585,  1.9011],\n",
            "        [-0.6262, -1.0612],\n",
            "        [ 0.9373,  1.9818],\n",
            "        [-2.0250, -0.0086],\n",
            "        [-2.2211,  1.3545],\n",
            "        [ 0.6492, -0.7922],\n",
            "        [ 0.1563, -0.8279],\n",
            "        [ 1.1852, -1.4746],\n",
            "        [ 0.1707, -0.2491],\n",
            "        [-0.9482,  0.5806],\n",
            "        [-0.6131, -0.9122],\n",
            "        [-0.3913, -1.8737],\n",
            "        [-0.9199, -1.2029],\n",
            "        [-0.0037,  0.6017],\n",
            "        [-0.6164,  1.7050],\n",
            "        [ 1.3917, -0.5392],\n",
            "        [-1.0985,  0.7235],\n",
            "        [ 0.2718, -0.1918],\n",
            "        [ 0.7885,  0.2677],\n",
            "        [ 0.6440, -0.3053],\n",
            "        [ 0.2194, -0.4471],\n",
            "        [-0.0497,  0.2005],\n",
            "        [ 2.4254,  1.1456],\n",
            "        [ 0.8478, -0.1659],\n",
            "        [-0.4595,  0.7520],\n",
            "        [-1.6187, -1.6055],\n",
            "        [ 1.0761, -0.3736],\n",
            "        [-0.8526, -1.2789],\n",
            "        [-0.1712,  0.1917],\n",
            "        [ 0.5586,  1.9343],\n",
            "        [ 0.5655, -0.2304],\n",
            "        [-0.3367,  0.5445],\n",
            "        [ 0.5535, -2.5428],\n",
            "        [ 1.0918, -0.7921],\n",
            "        [ 0.0423, -0.1731]])\n",
            "tensor([1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
            "        0., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task is to create a function f that is a single TLU, meaning that it summarizes x with weights a, b, c:\n",
        "\n",
        "$ax_0+bx_1+c$\n",
        "\n",
        "In Addition we are using a *sigmoid()* function as step function.\n",
        "\n",
        "$f = \\text{sigmoid}(ax_0+bx_1+c)$"
      ],
      "metadata": {
        "id": "z267w4G48rxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x, params):\n",
        "    a,b,c = params\n",
        "    d = a * x [:,0] + b * x [:,1] + c\n",
        "\n",
        "    return sigmoid(d)\n",
        "\n",
        "print(f(x, [3,-2,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_NvBnCGoLPx",
        "outputId": "e4feb78c-c270-42f0-aa96-f0de54502f2c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7.6971e-01, 2.3968e-01, 4.6192e-02, 7.9616e-01, 7.5812e-01, 9.8098e-01, 9.9864e-01, 9.0787e-01, 9.8712e-01, 1.4812e-01, 1.3230e-01, 1.3087e-01, 2.3231e-02, 8.9857e-01, 9.8283e-01, 2.5664e-01,\n",
            "        9.3780e-02, 8.6228e-01, 2.6002e-01, 9.9672e-01, 7.0278e-01, 9.1631e-01, 9.9109e-01, 1.0216e-03, 5.4472e-02, 1.6641e-02, 8.0314e-01, 1.7507e-01, 9.7561e-01, 1.2125e-01, 2.9646e-01, 8.9937e-02,\n",
            "        9.9921e-01, 3.5494e-01, 6.4367e-04, 9.9917e-01, 9.5396e-02, 1.2501e-01, 8.4759e-01, 9.9765e-01, 9.6319e-01, 1.4710e-03, 9.2763e-02, 9.8557e-01, 9.8938e-01, 7.3512e-02, 9.8145e-01, 9.0163e-01,\n",
            "        8.9450e-01, 9.9771e-01, 9.6892e-01, 3.7075e-01, 4.9179e-01, 9.9765e-01, 1.8825e-01, 1.7971e-01, 8.2720e-01, 9.8746e-01, 1.8810e-03, 1.5034e-01, 9.9893e-01, 9.9865e-01, 3.1266e-04, 1.5699e-01,\n",
            "        9.3052e-01, 3.7132e-01, 7.7620e-01, 4.6216e-01, 6.3180e-03, 2.3113e-04, 9.8936e-01, 9.5790e-01, 9.9945e-01, 8.8188e-01, 4.7158e-02, 7.2814e-01, 9.7271e-01, 6.5612e-01, 4.4658e-01, 1.3936e-02,\n",
            "        9.9808e-01, 2.3150e-02, 9.0016e-01, 9.4428e-01, 9.7188e-01, 9.2773e-01, 6.1065e-01, 9.9749e-01, 9.7967e-01, 1.3209e-01, 3.4408e-01, 9.9314e-01, 7.3107e-01, 5.2570e-01, 2.3274e-01, 9.5919e-01,\n",
            "        2.4990e-01, 9.9957e-01, 9.9716e-01, 8.1354e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to our TLU function, we need a loss function. Your task is to implement a absolute difference loss function, $∑|x_i-y_i|$, which counts the number of wrong guesses."
      ],
      "metadata": {
        "id": "UBiKkGKx-jVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(preds, targets): \n",
        "  return (preds - targets).abs().mean()"
      ],
      "metadata": {
        "id": "cwzyy281wI7Q"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to train your single TLU with the absolute difference loss function, use the following code. Choose an appropriate step weight `lr` and try to explain what is happing in each line."
      ],
      "metadata": {
        "id": "eGVNErmbvFxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.09\n",
        "params = torch.randn(3).requires_grad_()\n",
        "\n",
        "def apply_step(params, prn = True):\n",
        "    preds = f(x, params)\n",
        "    loss = mae(preds, y)\n",
        "    loss.backward()\n",
        "    params.data -= lr * params.grad.data\n",
        "    params.grad = None\n",
        "    if prn: print(params);print(loss.item())\n",
        "    return preds\n",
        "\n",
        "\n",
        "for i in range(50): apply_step(params)"
      ],
      "metadata": {
        "id": "EB5TYTNmyO3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5da941-fbd4-4570-f27f-beba6e71f484"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6497, -0.1971, -0.4248], requires_grad=True)\n",
            "0.5683578252792358\n",
            "tensor([-0.6386, -0.2101, -0.4241], requires_grad=True)\n",
            "0.5651119351387024\n",
            "tensor([-0.6273, -0.2231, -0.4235], requires_grad=True)\n",
            "0.5618411302566528\n",
            "tensor([-0.6160, -0.2361, -0.4228], requires_grad=True)\n",
            "0.5585464239120483\n",
            "tensor([-0.6046, -0.2492, -0.4220], requires_grad=True)\n",
            "0.5552288889884949\n",
            "tensor([-0.5931, -0.2622, -0.4212], requires_grad=True)\n",
            "0.5518896579742432\n",
            "tensor([-0.5816, -0.2752, -0.4204], requires_grad=True)\n",
            "0.5485299229621887\n",
            "tensor([-0.5700, -0.2882, -0.4195], requires_grad=True)\n",
            "0.5451509356498718\n",
            "tensor([-0.5583, -0.3013, -0.4186], requires_grad=True)\n",
            "0.5417540073394775\n",
            "tensor([-0.5465, -0.3143, -0.4177], requires_grad=True)\n",
            "0.5383406281471252\n",
            "tensor([-0.5347, -0.3273, -0.4167], requires_grad=True)\n",
            "0.5349120497703552\n",
            "tensor([-0.5229, -0.3403, -0.4156], requires_grad=True)\n",
            "0.5314698815345764\n",
            "tensor([-0.5110, -0.3532, -0.4146], requires_grad=True)\n",
            "0.5280154347419739\n",
            "tensor([-0.4990, -0.3662, -0.4134], requires_grad=True)\n",
            "0.5245504975318909\n",
            "tensor([-0.4869, -0.3791, -0.4123], requires_grad=True)\n",
            "0.5210764408111572\n",
            "tensor([-0.4749, -0.3920, -0.4111], requires_grad=True)\n",
            "0.5175950527191162\n",
            "tensor([-0.4628, -0.4049, -0.4098], requires_grad=True)\n",
            "0.5141077637672424\n",
            "tensor([-0.4506, -0.4177, -0.4085], requires_grad=True)\n",
            "0.5106163620948792\n",
            "tensor([-0.4384, -0.4306, -0.4072], requires_grad=True)\n",
            "0.5071223378181458\n",
            "tensor([-0.4262, -0.4433, -0.4058], requires_grad=True)\n",
            "0.5036274194717407\n",
            "tensor([-0.4139, -0.4560, -0.4043], requires_grad=True)\n",
            "0.500133216381073\n",
            "tensor([-0.4016, -0.4687, -0.4029], requires_grad=True)\n",
            "0.4966413378715515\n",
            "tensor([-0.3893, -0.4813, -0.4014], requires_grad=True)\n",
            "0.49315354228019714\n",
            "tensor([-0.3769, -0.4939, -0.3998], requires_grad=True)\n",
            "0.48967117071151733\n",
            "tensor([-0.3646, -0.5064, -0.3982], requires_grad=True)\n",
            "0.48619601130485535\n",
            "tensor([-0.3522, -0.5189, -0.3965], requires_grad=True)\n",
            "0.48272940516471863\n",
            "tensor([-0.3398, -0.5313, -0.3949], requires_grad=True)\n",
            "0.4792730212211609\n",
            "tensor([-0.3274, -0.5436, -0.3931], requires_grad=True)\n",
            "0.47582828998565674\n",
            "tensor([-0.3149, -0.5559, -0.3913], requires_grad=True)\n",
            "0.47239646315574646\n",
            "tensor([-0.3025, -0.5681, -0.3895], requires_grad=True)\n",
            "0.46897903084754944\n",
            "tensor([-0.2901, -0.5802, -0.3877], requires_grad=True)\n",
            "0.4655773937702179\n",
            "tensor([-0.2777, -0.5923, -0.3858], requires_grad=True)\n",
            "0.46219268441200256\n",
            "tensor([-0.2652, -0.6043, -0.3839], requires_grad=True)\n",
            "0.45882606506347656\n",
            "tensor([-0.2528, -0.6162, -0.3819], requires_grad=True)\n",
            "0.45547884702682495\n",
            "tensor([-0.2404, -0.6280, -0.3799], requires_grad=True)\n",
            "0.4521521031856537\n",
            "tensor([-0.2280, -0.6397, -0.3778], requires_grad=True)\n",
            "0.44884681701660156\n",
            "tensor([-0.2156, -0.6514, -0.3758], requires_grad=True)\n",
            "0.44556400179862976\n",
            "tensor([-0.2033, -0.6630, -0.3737], requires_grad=True)\n",
            "0.44230443239212036\n",
            "tensor([-0.1909, -0.6745, -0.3715], requires_grad=True)\n",
            "0.4390692114830017\n",
            "tensor([-0.1786, -0.6859, -0.3693], requires_grad=True)\n",
            "0.4358590841293335\n",
            "tensor([-0.1663, -0.6973, -0.3671], requires_grad=True)\n",
            "0.4326745569705963\n",
            "tensor([-0.1540, -0.7085, -0.3649], requires_grad=True)\n",
            "0.4295165240764618\n",
            "tensor([-0.1417, -0.7196, -0.3626], requires_grad=True)\n",
            "0.4263856112957001\n",
            "tensor([-0.1295, -0.7307, -0.3603], requires_grad=True)\n",
            "0.4232823848724365\n",
            "tensor([-0.1173, -0.7417, -0.3580], requires_grad=True)\n",
            "0.4202074110507965\n",
            "tensor([-0.1051, -0.7526, -0.3556], requires_grad=True)\n",
            "0.4171609580516815\n",
            "tensor([-0.0930, -0.7634, -0.3533], requires_grad=True)\n",
            "0.4141436815261841\n",
            "tensor([-0.0808, -0.7741, -0.3508], requires_grad=True)\n",
            "0.4111558198928833\n",
            "tensor([-0.0688, -0.7847, -0.3484], requires_grad=True)\n",
            "0.4081975817680359\n",
            "tensor([-0.0567, -0.7952, -0.3460], requires_grad=True)\n",
            "0.4052695035934448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a line of code that counts the number of wrong predictions, rounding your predictions with *round()*."
      ],
      "metadata": {
        "id": "h5_LNc1o_o2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = f(x, params)\n",
        "\n",
        "roundpreds = preds.round()\n",
        "print(roundpreds)\n",
        "print(y)\n",
        "wr_preds = (y - roundpreds).abs().sum()\n",
        "print(wr_preds)"
      ],
      "metadata": {
        "id": "EEUhyhyDxwMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7adb03-9a56-4719-889a-960b86aa871f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
            "        1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
            "        0., 1., 1., 0.], grad_fn=<RoundBackward0>)\n",
            "tensor([1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
            "        0., 1., 1., 1.])\n",
            "tensor(27., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    }
  ]
}
